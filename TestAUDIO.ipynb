{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP70hDQpW2lpP2UHUUvAGkn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Youngstg/Test_Multimodal/blob/main/TestAUDIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: MIREX Emotion Dataset dari Kaggle\n",
        "Modalitas: Audio (WAV files)\n",
        "Model: PANNs (Pre-trained Audio Neural Networks)\n",
        "\n",
        "Paper: \"PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition\""
      ],
      "metadata": {
        "id": "1l2syscRSIJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. INSTALASI DAN IMPORT LIBRARY"
      ],
      "metadata": {
        "id": "ZNn3RbZzSNPP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDUNrVpvQ2i1",
        "outputId": "b8b2db46-0afa-47db-84db-56c8ee1fe3ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "✓ Installation complete!\n",
            "\n",
            "✓ Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing required packages...\")\n",
        "!pip install -q kagglehub\n",
        "!pip install -q panns-inference  # Much simpler!\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q librosa soundfile\n",
        "!pip install -q scikit-learn pandas numpy\n",
        "\n",
        "print(\"✓ Installation complete!\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from panns_inference import AudioTagging  # PANNs made easy!\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'\\n✓ Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. DOWNLOAD DATASET & LOAD PRE-TRAINED PANNS"
      ],
      "metadata": {
        "id": "xiB5C15dSfe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DOWNLOADING MIREX DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"imsparsh/multimodal-mirex-emotion-dataset\")\n",
        "print(f\"✓ Path to dataset files: {path}\")\n",
        "\n",
        "# Check audio directory\n",
        "audio_dir = os.path.join(path, 'dataset', 'Audio')\n",
        "print(f\"\\n✓ Audio directory: {audio_dir}\")\n",
        "print(f\"✓ Audio directory exists: {os.path.exists(audio_dir)}\")\n",
        "\n",
        "if os.path.exists(audio_dir):\n",
        "    audio_files = [f for f in os.listdir(audio_dir) if f.endswith('.wav') or f.endswith('.mp3')]\n",
        "    print(f\"✓ Found {len(audio_files)} audio files\")\n",
        "    if len(audio_files) > 0:\n",
        "        print(f\"  Sample files: {audio_files[:5]}\")\n",
        "else:\n",
        "    print(\"⚠️ Audio directory not found! Checking alternatives...\")\n",
        "    # Try alternative paths\n",
        "    for alt_dir in ['Audio', 'audio', 'WAV', 'wav']:\n",
        "        alt_path = os.path.join(path, 'dataset', alt_dir)\n",
        "        if os.path.exists(alt_path):\n",
        "            audio_dir = alt_path\n",
        "            print(f\"✓ Found audio at: {audio_dir}\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HnZsodYSgSI",
        "outputId": "7092f67e-3e47-4289-ec76-e6521f87ee54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DOWNLOADING MIREX DATASET\n",
            "================================================================================\n",
            "Using Colab cache for faster access to the 'multimodal-mirex-emotion-dataset' dataset.\n",
            "✓ Path to dataset files: /kaggle/input/multimodal-mirex-emotion-dataset\n",
            "\n",
            "✓ Audio directory: /kaggle/input/multimodal-mirex-emotion-dataset/dataset/Audio\n",
            "✓ Audio directory exists: True\n",
            "✓ Found 903 audio files\n",
            "  Sample files: ['326.mp3', '149.mp3', '898.mp3', '011.mp3', '434.mp3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. LOAD PRE-TRAINED PANNS (USING panns-inference)"
      ],
      "metadata": {
        "id": "qd1W8FEdSj7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING PRE-TRAINED PANNS MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Initialize PANNs Audio Tagging model (auto-downloads weights!)\n",
        "at = AudioTagging(checkpoint_path=None, device=device)  # Auto download\n",
        "\n",
        "print(\"✓ PANNs model loaded successfully!\")\n",
        "print(\"  Model: Cnn14\")\n",
        "print(\"  Trained on: AudioSet (2M+ audio clips)\")\n",
        "print(\"  Embedding dimension: 2048\")\n",
        "print(\"  Checkpoint auto-downloaded by panns-inference\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vvheGfBSmdy",
        "outputId": "1b0fa442-ee83-45f1-d892-97890c7d1741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING PRE-TRAINED PANNS MODEL\n",
            "================================================================================\n",
            "Checkpoint path: /root/panns_data/Cnn14_mAP=0.431.pth\n",
            "Using CPU.\n",
            "✓ PANNs model loaded successfully!\n",
            "  Model: Cnn14\n",
            "  Trained on: AudioSet (2M+ audio clips)\n",
            "  Embedding dimension: 2048\n",
            "  Checkpoint auto-downloaded by panns-inference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. AUDIO FEATURE EXTRACTION (USING panns-inference)"
      ],
      "metadata": {
        "id": "Y16WYZTzSoMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio_embedding(audio_path, at_model, sr=32000, duration=10):\n",
        "    \"\"\"\n",
        "    Extract PANNs embedding from audio file using panns-inference\n",
        "\n",
        "    Args:\n",
        "        audio_path: path to audio file\n",
        "        at_model: AudioTagging model from panns-inference\n",
        "        sr: sample rate\n",
        "        duration: audio duration in seconds\n",
        "\n",
        "    Returns:\n",
        "        embedding: (2048,) PANNs embedding\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio\n",
        "        audio, orig_sr = librosa.load(audio_path, sr=sr, duration=duration)\n",
        "\n",
        "        # Pad if too short\n",
        "        target_length = sr * duration\n",
        "        if len(audio) < target_length:\n",
        "            audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
        "        else:\n",
        "            audio = audio[:target_length]\n",
        "\n",
        "        # Inference with PANNs (returns clipwise_output and embedding)\n",
        "        (clipwise_output, embedding) = at_model.inference(audio[None, :])\n",
        "\n",
        "        # embedding shape: (1, 2048)\n",
        "        embedding = embedding[0]  # (2048,)\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "l6MTYIqBSqGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. LOAD CLUSTER LABELS"
      ],
      "metadata": {
        "id": "V6xkTiU-Sr9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cluster_labels(dataset_path):\n",
        "    \"\"\"\n",
        "    Load cluster labels from clusters.txt\n",
        "    \"\"\"\n",
        "    clusters_path = os.path.join(dataset_path, 'dataset', 'clusters.txt')\n",
        "    cluster_labels = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"LOADING CLUSTER LABELS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if os.path.exists(clusters_path):\n",
        "        with open(clusters_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            lines = f.readlines()\n",
        "            cluster_labels = [line.strip() for line in lines if line.strip()]\n",
        "\n",
        "        unique_clusters = sorted(set(cluster_labels))\n",
        "        print(f\"✓ Loaded {len(cluster_labels)} cluster labels\")\n",
        "        print(f\"✓ Unique clusters: {unique_clusters}\")\n",
        "\n",
        "        from collections import Counter\n",
        "        cluster_counts = Counter(cluster_labels)\n",
        "        print(f\"\\nCluster distribution:\")\n",
        "        for cluster, count in sorted(cluster_counts.items()):\n",
        "            print(f\"  {cluster}: {count} songs\")\n",
        "    else:\n",
        "        print(\"❌ clusters.txt not found!\")\n",
        "        return []\n",
        "\n",
        "    return cluster_labels\n",
        "\n",
        "cluster_labels = load_cluster_labels(path)\n",
        "\n",
        "# Create song_id to cluster mapping\n",
        "song_cluster_map = {}\n",
        "for idx in range(len(cluster_labels)):\n",
        "    song_id_0 = str(idx).zfill(3)\n",
        "    song_id_1 = str(idx + 1).zfill(3)\n",
        "    song_cluster_map[song_id_0] = cluster_labels[idx]\n",
        "    song_cluster_map[song_id_1] = cluster_labels[idx]\n",
        "\n",
        "print(f\"\\n✓ Created mappings for {len(song_cluster_map)} song IDs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMK5p8XWSvSo",
        "outputId": "42cba071-7c5c-4f69-835b-b8da49da9da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING CLUSTER LABELS\n",
            "================================================================================\n",
            "✓ Loaded 903 cluster labels\n",
            "✓ Unique clusters: ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5']\n",
            "\n",
            "Cluster distribution:\n",
            "  Cluster 1: 170 songs\n",
            "  Cluster 2: 164 songs\n",
            "  Cluster 3: 215 songs\n",
            "  Cluster 4: 191 songs\n",
            "  Cluster 5: 163 songs\n",
            "\n",
            "✓ Created mappings for 904 song IDs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. AUDIO PREPROCESSING & FEATURE EXTRACTION"
      ],
      "metadata": {
        "id": "4v2121aySxB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING AUDIO DATA & EXTRACTING EMBEDDINGS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find audio files\n",
        "audio_files_found = [f for f in os.listdir(audio_dir) if f.endswith('.wav') or f.endswith('.mp3')]\n",
        "print(f\"Processing {len(audio_files_found)} audio files...\")\n",
        "print(\"Extracting PANNs embeddings (this may take a while)...\\n\")\n",
        "\n",
        "audio_data_list = []\n",
        "matched = 0\n",
        "failed = 0\n",
        "no_cluster = 0\n",
        "\n",
        "for idx, audio_file in enumerate(audio_files_found):\n",
        "    if idx % 20 == 0 and idx > 0:\n",
        "        print(f\"  Progress: {idx}/{len(audio_files_found)} files processed...\")\n",
        "\n",
        "    # Extract song ID\n",
        "    song_id = audio_file.replace('.wav', '').replace('.mp3', '')\n",
        "    song_id_clean = ''.join(filter(str.isdigit, song_id))\n",
        "    if song_id_clean:\n",
        "        song_id = song_id_clean.zfill(3)\n",
        "\n",
        "    # Check cluster mapping\n",
        "    if song_id not in song_cluster_map:\n",
        "        no_cluster += 1\n",
        "        if no_cluster <= 3:\n",
        "            print(f\"  ⚠️ No cluster for: {audio_file} (ID: {song_id})\")\n",
        "        continue\n",
        "\n",
        "    # Extract PANNs embedding\n",
        "    audio_path = os.path.join(audio_dir, audio_file)\n",
        "    embedding = extract_audio_embedding(audio_path, at, sr=32000, duration=10)\n",
        "\n",
        "    if embedding is not None:\n",
        "        audio_data_list.append({\n",
        "            'song_id': song_id,\n",
        "            'embedding': embedding,\n",
        "            'cluster': song_cluster_map[song_id]\n",
        "        })\n",
        "        matched += 1\n",
        "\n",
        "        if matched <= 3:\n",
        "            print(f\"  ✓ Loaded: {audio_file} → {song_id} → {song_cluster_map[song_id]} (emb: {embedding.shape})\")\n",
        "    else:\n",
        "        failed += 1\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"AUDIO LOADING SUMMARY:\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"✓ Successfully loaded: {matched} audio files\")\n",
        "print(f\"⚠️ No cluster mapping: {no_cluster} files\")\n",
        "print(f\"❌ Failed to process: {failed} files\")\n",
        "\n",
        "# Create DataFrame\n",
        "if len(audio_data_list) > 0:\n",
        "    df = pd.DataFrame(audio_data_list)\n",
        "    print(f\"\\n✓ Dataset shape: {df.shape}\")\n",
        "    print(f\"\\nCluster distribution:\")\n",
        "    print(df['cluster'].value_counts())\n",
        "else:\n",
        "    raise ValueError(\"No audio data loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSXbRAHJSzig",
        "outputId": "e5159cbb-b85c-4a86-c42e-206ac6766288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING AUDIO DATA & EXTRACTING EMBEDDINGS\n",
            "================================================================================\n",
            "Processing 903 audio files...\n",
            "Extracting PANNs embeddings (this may take a while)...\n",
            "\n",
            "  ✓ Loaded: 326.mp3 → 326 → Cluster 2 (emb: (2048,))\n",
            "  ✓ Loaded: 149.mp3 → 149 → Cluster 1 (emb: (2048,))\n",
            "  ✓ Loaded: 898.mp3 → 898 → Cluster 5 (emb: (2048,))\n",
            "  Progress: 20/903 files processed...\n",
            "  Progress: 40/903 files processed...\n",
            "  Progress: 60/903 files processed...\n",
            "  Progress: 80/903 files processed...\n",
            "  Progress: 100/903 files processed...\n",
            "  Progress: 120/903 files processed...\n",
            "  Progress: 140/903 files processed...\n",
            "  Progress: 160/903 files processed...\n",
            "  Progress: 180/903 files processed...\n",
            "  Progress: 200/903 files processed...\n",
            "  Progress: 220/903 files processed...\n",
            "  Progress: 240/903 files processed...\n",
            "  Progress: 260/903 files processed...\n",
            "  Progress: 280/903 files processed...\n",
            "  Progress: 300/903 files processed...\n",
            "  Progress: 320/903 files processed...\n",
            "  Progress: 340/903 files processed...\n",
            "  Progress: 360/903 files processed...\n",
            "  Progress: 380/903 files processed...\n",
            "  Progress: 400/903 files processed...\n",
            "  Progress: 420/903 files processed...\n",
            "  Progress: 440/903 files processed...\n",
            "  Progress: 460/903 files processed...\n",
            "  Progress: 480/903 files processed...\n",
            "  Progress: 500/903 files processed...\n",
            "  Progress: 520/903 files processed...\n",
            "  Progress: 540/903 files processed...\n",
            "  Progress: 560/903 files processed...\n",
            "  Progress: 580/903 files processed...\n",
            "  Progress: 600/903 files processed...\n",
            "  Progress: 620/903 files processed...\n",
            "  Progress: 640/903 files processed...\n",
            "  Progress: 660/903 files processed...\n",
            "  Progress: 680/903 files processed...\n",
            "  Progress: 700/903 files processed...\n",
            "  Progress: 720/903 files processed...\n",
            "  Progress: 740/903 files processed...\n",
            "  Progress: 760/903 files processed...\n",
            "  Progress: 780/903 files processed...\n",
            "  Progress: 800/903 files processed...\n",
            "  Progress: 820/903 files processed...\n",
            "  Progress: 840/903 files processed...\n",
            "  Progress: 860/903 files processed...\n",
            "  Progress: 880/903 files processed...\n",
            "  Progress: 900/903 files processed...\n",
            "\n",
            "================================================================================\n",
            "AUDIO LOADING SUMMARY:\n",
            "================================================================================\n",
            "✓ Successfully loaded: 903 audio files\n",
            "⚠️ No cluster mapping: 0 files\n",
            "❌ Failed to process: 0 files\n",
            "\n",
            "✓ Dataset shape: (903, 3)\n",
            "\n",
            "Cluster distribution:\n",
            "cluster\n",
            "Cluster 3    215\n",
            "Cluster 4    191\n",
            "Cluster 1    169\n",
            "Cluster 2    164\n",
            "Cluster 5    164\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. DATASET CLASS (SIMPLIFIED)"
      ],
      "metadata": {
        "id": "jEJr1Fp7S12r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "\n",
        "        # Embedding already extracted by panns-inference\n",
        "        embedding = torch.FloatTensor(item['embedding'])\n",
        "        label = item['label']\n",
        "\n",
        "        return {\n",
        "            'embedding': embedding,\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "oStzjtWbS6iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. EMOTION CLASSIFIER (SIMPLIFIED)"
      ],
      "metadata": {
        "id": "H3k05f0DS9JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PANNsEmotionClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple classifier on top of pre-extracted PANNs embeddings\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, input_dim=2048, dropout=0.5):\n",
        "        super(PANNsEmotionClassifier, self).__init__()\n",
        "\n",
        "        # Classifier head (embeddings already extracted)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, embedding):\n",
        "        # Embeddings already computed, just classify\n",
        "        logits = self.classifier(embedding)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "riBJws22S-_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. LABEL ENCODING"
      ],
      "metadata": {
        "id": "gsOdHFz5TA1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ENCODING LABELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['cluster'])\n",
        "\n",
        "print(f\"✓ Cluster classes: {label_encoder.classes_}\")\n",
        "print(f\"✓ Number of clusters: {len(label_encoder.classes_)}\")\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "for cluster, count in df['cluster'].value_counts().items():\n",
        "    encoded = df[df['cluster'] == cluster]['label'].iloc[0]\n",
        "    print(f\"  {encoded}: {cluster} - {count} samples\")\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Calculate class weights\n",
        "y_labels = df['label'].values\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_labels), y=y_labels)\n",
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "print(f\"\\n✓ Class weights: {class_weights.cpu().numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eybCrfd6TDyu",
        "outputId": "5eb41540-67f7-4b9d-d232-fc0d7fdbab59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ENCODING LABELS\n",
            "================================================================================\n",
            "✓ Cluster classes: ['Cluster 1' 'Cluster 2' 'Cluster 3' 'Cluster 4' 'Cluster 5']\n",
            "✓ Number of clusters: 5\n",
            "\n",
            "Class distribution:\n",
            "  2: Cluster 3 - 215 samples\n",
            "  3: Cluster 4 - 191 samples\n",
            "  0: Cluster 1 - 169 samples\n",
            "  1: Cluster 2 - 164 samples\n",
            "  4: Cluster 5 - 164 samples\n",
            "\n",
            "✓ Class weights: [1.068639  1.1012195 0.84      0.9455497 1.1012195]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. TRAINING & EVALUATION FUNCTIONS (SIMPLIFIED)"
      ],
      "metadata": {
        "id": "SfKvQV_rTGZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        embedding = batch['embedding'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(embedding)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Predictions\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            embedding = batch['embedding'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(embedding)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Predictions\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        true_labels, predictions, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    return avg_loss, accuracy, precision, recall, f1, predictions, true_labels"
      ],
      "metadata": {
        "id": "7e_vvbC6TJCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. 5-FOLD CROSS VALIDATION"
      ],
      "metadata": {
        "id": "b7IfEz9iTL9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 30\n",
        "N_FOLDS = 5\n",
        "WEIGHT_DECAY = 0.01\n",
        "EARLY_STOPPING_PATIENCE = 7\n",
        "DROPOUT = 0.5\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"HYPERPARAMETERS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Dropout: {DROPOUT}\")\n",
        "print(f\"PANNs: Pre-extracted embeddings (2048-dim)\")\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "\n",
        "# Prepare data\n",
        "X = df.index.values\n",
        "y = df['label'].values\n",
        "\n",
        "# 5-Fold Cross Validation\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STARTING 5-FOLD CROSS VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fold_results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Split data\n",
        "    train_data = df.iloc[train_idx].reset_index(drop=True)\n",
        "    val_data = df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    print(f\"Train size: {len(train_data)}, Val size: {len(val_data)}\")\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = AudioDataset(train_data)\n",
        "    val_dataset = AudioDataset(val_data)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Initialize model\n",
        "    model = PANNsEmotionClassifier(\n",
        "        num_classes=num_classes,\n",
        "        input_dim=2048,\n",
        "        dropout=DROPOUT\n",
        "    )\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    # Scheduler\n",
        "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "    # Training loop\n",
        "    best_val_f1 = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1, _, _ = evaluate(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        # Update scheduler\n",
        "        scheduler.step(val_f1)\n",
        "\n",
        "        # Overfitting gap\n",
        "        overfit_gap = train_acc - val_acc\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "        print(f\"Overfitting Gap: {overfit_gap:.4f}\")\n",
        "\n",
        "        if overfit_gap > 0.2:\n",
        "            print(f\"  ⚠️ Overfitting detected!\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            torch.save(model.state_dict(), f'best_panns_model_fold{fold+1}.pt')\n",
        "            patience_counter = 0\n",
        "            print(f\"  ✓ New best F1: {best_val_f1:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  No improvement ({patience_counter}/{EARLY_STOPPING_PATIENCE})\")\n",
        "\n",
        "            if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
        "                print(f\"  Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load(f'best_panns_model_fold{fold+1}.pt'))\n",
        "    val_loss, val_acc, val_precision, val_recall, val_f1, predictions, true_labels = evaluate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"FOLD {fold + 1} FINAL RESULTS:\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Accuracy:  {val_acc:.4f}\")\n",
        "    print(f\"Precision: {val_precision:.4f}\")\n",
        "    print(f\"Recall:    {val_recall:.4f}\")\n",
        "    print(f\"F1-Score:  {val_f1:.4f}\")\n",
        "\n",
        "    # Store results\n",
        "    fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'accuracy': val_acc,\n",
        "        'precision': val_precision,\n",
        "        'recall': val_recall,\n",
        "        'f1': val_f1\n",
        "    })\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        true_labels, predictions,\n",
        "        target_names=label_encoder.classes_,\n",
        "        digits=4,\n",
        "        zero_division=0\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0eQnbQFTR0d",
        "outputId": "8f17c850-efe7-4319-c04e-49316578453a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "HYPERPARAMETERS\n",
            "================================================================================\n",
            "Batch size: 16\n",
            "Learning rate: 0.0001\n",
            "Epochs: 30\n",
            "Dropout: 0.5\n",
            "PANNs: Pre-extracted embeddings (2048-dim)\n",
            "Total samples: 903\n",
            "\n",
            "================================================================================\n",
            "STARTING 5-FOLD CROSS VALIDATION\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "FOLD 1/5\n",
            "================================================================================\n",
            "Train size: 722, Val size: 181\n",
            "\n",
            "Epoch 1/30\n",
            "Train Loss: 1.6213, Train Acc: 0.2175\n",
            "Val Loss: 1.5661, Val Acc: 0.3702, Val F1: 0.3112\n",
            "Overfitting Gap: -0.1527\n",
            "  ✓ New best F1: 0.3112\n",
            "\n",
            "Epoch 2/30\n",
            "Train Loss: 1.5574, Train Acc: 0.3061\n",
            "Val Loss: 1.5219, Val Acc: 0.4088, Val F1: 0.3462\n",
            "Overfitting Gap: -0.1027\n",
            "  ✓ New best F1: 0.3462\n",
            "\n",
            "Epoch 3/30\n",
            "Train Loss: 1.5273, Train Acc: 0.3421\n",
            "Val Loss: 1.4883, Val Acc: 0.4254, Val F1: 0.3819\n",
            "Overfitting Gap: -0.0833\n",
            "  ✓ New best F1: 0.3819\n",
            "\n",
            "Epoch 4/30\n",
            "Train Loss: 1.4910, Train Acc: 0.3324\n",
            "Val Loss: 1.4644, Val Acc: 0.4365, Val F1: 0.3986\n",
            "Overfitting Gap: -0.1041\n",
            "  ✓ New best F1: 0.3986\n",
            "\n",
            "Epoch 5/30\n",
            "Train Loss: 1.4607, Train Acc: 0.3753\n",
            "Val Loss: 1.4395, Val Acc: 0.4420, Val F1: 0.4007\n",
            "Overfitting Gap: -0.0666\n",
            "  ✓ New best F1: 0.4007\n",
            "\n",
            "Epoch 6/30\n",
            "Train Loss: 1.4201, Train Acc: 0.3975\n",
            "Val Loss: 1.4214, Val Acc: 0.4475, Val F1: 0.4029\n",
            "Overfitting Gap: -0.0500\n",
            "  ✓ New best F1: 0.4029\n",
            "\n",
            "Epoch 7/30\n",
            "Train Loss: 1.4312, Train Acc: 0.4017\n",
            "Val Loss: 1.4074, Val Acc: 0.4586, Val F1: 0.4140\n",
            "Overfitting Gap: -0.0569\n",
            "  ✓ New best F1: 0.4140\n",
            "\n",
            "Epoch 8/30\n",
            "Train Loss: 1.4499, Train Acc: 0.3920\n",
            "Val Loss: 1.3973, Val Acc: 0.4530, Val F1: 0.4140\n",
            "Overfitting Gap: -0.0611\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 9/30\n",
            "Train Loss: 1.3916, Train Acc: 0.4252\n",
            "Val Loss: 1.3917, Val Acc: 0.4420, Val F1: 0.3992\n",
            "Overfitting Gap: -0.0168\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 10/30\n",
            "Train Loss: 1.3796, Train Acc: 0.4307\n",
            "Val Loss: 1.3825, Val Acc: 0.4641, Val F1: 0.4241\n",
            "Overfitting Gap: -0.0333\n",
            "  ✓ New best F1: 0.4241\n",
            "\n",
            "Epoch 11/30\n",
            "Train Loss: 1.3886, Train Acc: 0.4183\n",
            "Val Loss: 1.3791, Val Acc: 0.4475, Val F1: 0.3996\n",
            "Overfitting Gap: -0.0292\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 12/30\n",
            "Train Loss: 1.3644, Train Acc: 0.4446\n",
            "Val Loss: 1.3717, Val Acc: 0.4475, Val F1: 0.4015\n",
            "Overfitting Gap: -0.0029\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 13/30\n",
            "Train Loss: 1.3536, Train Acc: 0.4377\n",
            "Val Loss: 1.3647, Val Acc: 0.4586, Val F1: 0.4227\n",
            "Overfitting Gap: -0.0209\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 14/30\n",
            "Train Loss: 1.3975, Train Acc: 0.4418\n",
            "Val Loss: 1.3651, Val Acc: 0.4641, Val F1: 0.4309\n",
            "Overfitting Gap: -0.0223\n",
            "  ✓ New best F1: 0.4309\n",
            "\n",
            "Epoch 15/30\n",
            "Train Loss: 1.3557, Train Acc: 0.4266\n",
            "Val Loss: 1.3605, Val Acc: 0.4751, Val F1: 0.4386\n",
            "Overfitting Gap: -0.0485\n",
            "  ✓ New best F1: 0.4386\n",
            "\n",
            "Epoch 16/30\n",
            "Train Loss: 1.3681, Train Acc: 0.4488\n",
            "Val Loss: 1.3610, Val Acc: 0.4641, Val F1: 0.4141\n",
            "Overfitting Gap: -0.0153\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 17/30\n",
            "Train Loss: 1.3395, Train Acc: 0.4515\n",
            "Val Loss: 1.3535, Val Acc: 0.4696, Val F1: 0.4349\n",
            "Overfitting Gap: -0.0181\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 18/30\n",
            "Train Loss: 1.3259, Train Acc: 0.4432\n",
            "Val Loss: 1.3532, Val Acc: 0.4586, Val F1: 0.4163\n",
            "Overfitting Gap: -0.0154\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 19/30\n",
            "Train Loss: 1.3322, Train Acc: 0.4515\n",
            "Val Loss: 1.3456, Val Acc: 0.4807, Val F1: 0.4535\n",
            "Overfitting Gap: -0.0291\n",
            "  ✓ New best F1: 0.4535\n",
            "\n",
            "Epoch 20/30\n",
            "Train Loss: 1.3353, Train Acc: 0.4723\n",
            "Val Loss: 1.3413, Val Acc: 0.4696, Val F1: 0.4274\n",
            "Overfitting Gap: 0.0027\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 21/30\n",
            "Train Loss: 1.3039, Train Acc: 0.4612\n",
            "Val Loss: 1.3426, Val Acc: 0.4862, Val F1: 0.4538\n",
            "Overfitting Gap: -0.0250\n",
            "  ✓ New best F1: 0.4538\n",
            "\n",
            "Epoch 22/30\n",
            "Train Loss: 1.3042, Train Acc: 0.4543\n",
            "Val Loss: 1.3504, Val Acc: 0.4751, Val F1: 0.4405\n",
            "Overfitting Gap: -0.0208\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 23/30\n",
            "Train Loss: 1.3347, Train Acc: 0.4543\n",
            "Val Loss: 1.3412, Val Acc: 0.4862, Val F1: 0.4548\n",
            "Overfitting Gap: -0.0319\n",
            "  ✓ New best F1: 0.4548\n",
            "\n",
            "Epoch 24/30\n",
            "Train Loss: 1.3062, Train Acc: 0.4765\n",
            "Val Loss: 1.3390, Val Acc: 0.4751, Val F1: 0.4480\n",
            "Overfitting Gap: 0.0013\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 25/30\n",
            "Train Loss: 1.2856, Train Acc: 0.4571\n",
            "Val Loss: 1.3377, Val Acc: 0.4641, Val F1: 0.4290\n",
            "Overfitting Gap: -0.0070\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 26/30\n",
            "Train Loss: 1.3512, Train Acc: 0.4668\n",
            "Val Loss: 1.3376, Val Acc: 0.4751, Val F1: 0.4382\n",
            "Overfitting Gap: -0.0084\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 27/30\n",
            "Train Loss: 1.3106, Train Acc: 0.4681\n",
            "Val Loss: 1.3370, Val Acc: 0.4696, Val F1: 0.4405\n",
            "Overfitting Gap: -0.0015\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 28/30\n",
            "Train Loss: 1.2790, Train Acc: 0.4765\n",
            "Val Loss: 1.3386, Val Acc: 0.4696, Val F1: 0.4234\n",
            "Overfitting Gap: 0.0068\n",
            "  No improvement (5/7)\n",
            "\n",
            "Epoch 29/30\n",
            "Train Loss: 1.2688, Train Acc: 0.4695\n",
            "Val Loss: 1.3344, Val Acc: 0.4751, Val F1: 0.4398\n",
            "Overfitting Gap: -0.0056\n",
            "  No improvement (6/7)\n",
            "\n",
            "Epoch 30/30\n",
            "Train Loss: 1.2713, Train Acc: 0.4584\n",
            "Val Loss: 1.3346, Val Acc: 0.4641, Val F1: 0.4316\n",
            "Overfitting Gap: -0.0056\n",
            "  No improvement (7/7)\n",
            "  Early stopping triggered!\n",
            "\n",
            "================================================================================\n",
            "FOLD 1 FINAL RESULTS:\n",
            "================================================================================\n",
            "Accuracy:  0.4862\n",
            "Precision: 0.4690\n",
            "Recall:    0.4862\n",
            "F1-Score:  0.4548\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 1     0.3571    0.1471    0.2083        34\n",
            "   Cluster 2     0.5161    0.4848    0.5000        33\n",
            "   Cluster 3     0.5273    0.6744    0.5918        43\n",
            "   Cluster 4     0.4583    0.2895    0.3548        38\n",
            "   Cluster 5     0.4737    0.8182    0.6000        33\n",
            "\n",
            "    accuracy                         0.4862       181\n",
            "   macro avg     0.4665    0.4828    0.4510       181\n",
            "weighted avg     0.4690    0.4862    0.4548       181\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FOLD 2/5\n",
            "================================================================================\n",
            "Train size: 722, Val size: 181\n",
            "\n",
            "Epoch 1/30\n",
            "Train Loss: 1.6193, Train Acc: 0.2119\n",
            "Val Loss: 1.5780, Val Acc: 0.3370, Val F1: 0.3050\n",
            "Overfitting Gap: -0.1251\n",
            "  ✓ New best F1: 0.3050\n",
            "\n",
            "Epoch 2/30\n",
            "Train Loss: 1.5757, Train Acc: 0.2992\n",
            "Val Loss: 1.5317, Val Acc: 0.3867, Val F1: 0.3347\n",
            "Overfitting Gap: -0.0876\n",
            "  ✓ New best F1: 0.3347\n",
            "\n",
            "Epoch 3/30\n",
            "Train Loss: 1.5360, Train Acc: 0.3352\n",
            "Val Loss: 1.4856, Val Acc: 0.4088, Val F1: 0.3754\n",
            "Overfitting Gap: -0.0737\n",
            "  ✓ New best F1: 0.3754\n",
            "\n",
            "Epoch 4/30\n",
            "Train Loss: 1.5016, Train Acc: 0.3573\n",
            "Val Loss: 1.4525, Val Acc: 0.4144, Val F1: 0.3670\n",
            "Overfitting Gap: -0.0570\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 5/30\n",
            "Train Loss: 1.4611, Train Acc: 0.3947\n",
            "Val Loss: 1.4164, Val Acc: 0.4199, Val F1: 0.3820\n",
            "Overfitting Gap: -0.0252\n",
            "  ✓ New best F1: 0.3820\n",
            "\n",
            "Epoch 6/30\n",
            "Train Loss: 1.4632, Train Acc: 0.3753\n",
            "Val Loss: 1.3902, Val Acc: 0.4199, Val F1: 0.3706\n",
            "Overfitting Gap: -0.0445\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 7/30\n",
            "Train Loss: 1.4390, Train Acc: 0.3947\n",
            "Val Loss: 1.3736, Val Acc: 0.4199, Val F1: 0.3698\n",
            "Overfitting Gap: -0.0252\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 8/30\n",
            "Train Loss: 1.4045, Train Acc: 0.4169\n",
            "Val Loss: 1.3617, Val Acc: 0.4309, Val F1: 0.3934\n",
            "Overfitting Gap: -0.0140\n",
            "  ✓ New best F1: 0.3934\n",
            "\n",
            "Epoch 9/30\n",
            "Train Loss: 1.4174, Train Acc: 0.4058\n",
            "Val Loss: 1.3520, Val Acc: 0.4254, Val F1: 0.3921\n",
            "Overfitting Gap: -0.0196\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 10/30\n",
            "Train Loss: 1.3794, Train Acc: 0.4100\n",
            "Val Loss: 1.3425, Val Acc: 0.4199, Val F1: 0.3889\n",
            "Overfitting Gap: -0.0099\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 11/30\n",
            "Train Loss: 1.4061, Train Acc: 0.4169\n",
            "Val Loss: 1.3425, Val Acc: 0.4144, Val F1: 0.3825\n",
            "Overfitting Gap: 0.0025\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 12/30\n",
            "Train Loss: 1.3727, Train Acc: 0.4280\n",
            "Val Loss: 1.3385, Val Acc: 0.4254, Val F1: 0.3926\n",
            "Overfitting Gap: 0.0026\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 13/30\n",
            "Train Loss: 1.3506, Train Acc: 0.4391\n",
            "Val Loss: 1.3373, Val Acc: 0.4365, Val F1: 0.4034\n",
            "Overfitting Gap: 0.0026\n",
            "  ✓ New best F1: 0.4034\n",
            "\n",
            "Epoch 14/30\n",
            "Train Loss: 1.3421, Train Acc: 0.4321\n",
            "Val Loss: 1.3410, Val Acc: 0.4365, Val F1: 0.4007\n",
            "Overfitting Gap: -0.0043\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 15/30\n",
            "Train Loss: 1.3213, Train Acc: 0.4654\n",
            "Val Loss: 1.3319, Val Acc: 0.4199, Val F1: 0.3844\n",
            "Overfitting Gap: 0.0455\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 16/30\n",
            "Train Loss: 1.3392, Train Acc: 0.4432\n",
            "Val Loss: 1.3303, Val Acc: 0.4365, Val F1: 0.4039\n",
            "Overfitting Gap: 0.0067\n",
            "  ✓ New best F1: 0.4039\n",
            "\n",
            "Epoch 17/30\n",
            "Train Loss: 1.3282, Train Acc: 0.4654\n",
            "Val Loss: 1.3292, Val Acc: 0.4199, Val F1: 0.3858\n",
            "Overfitting Gap: 0.0455\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 18/30\n",
            "Train Loss: 1.2958, Train Acc: 0.4488\n",
            "Val Loss: 1.3318, Val Acc: 0.4420, Val F1: 0.4102\n",
            "Overfitting Gap: 0.0068\n",
            "  ✓ New best F1: 0.4102\n",
            "\n",
            "Epoch 19/30\n",
            "Train Loss: 1.3175, Train Acc: 0.4626\n",
            "Val Loss: 1.3287, Val Acc: 0.4365, Val F1: 0.4083\n",
            "Overfitting Gap: 0.0261\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 20/30\n",
            "Train Loss: 1.2980, Train Acc: 0.4668\n",
            "Val Loss: 1.3290, Val Acc: 0.4199, Val F1: 0.3860\n",
            "Overfitting Gap: 0.0469\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 21/30\n",
            "Train Loss: 1.3588, Train Acc: 0.4349\n",
            "Val Loss: 1.3258, Val Acc: 0.4199, Val F1: 0.3927\n",
            "Overfitting Gap: 0.0150\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 22/30\n",
            "Train Loss: 1.3092, Train Acc: 0.4654\n",
            "Val Loss: 1.3247, Val Acc: 0.4144, Val F1: 0.3845\n",
            "Overfitting Gap: 0.0510\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 23/30\n",
            "Train Loss: 1.3187, Train Acc: 0.4432\n",
            "Val Loss: 1.3243, Val Acc: 0.4309, Val F1: 0.3955\n",
            "Overfitting Gap: 0.0123\n",
            "  No improvement (5/7)\n",
            "\n",
            "Epoch 24/30\n",
            "Train Loss: 1.3165, Train Acc: 0.4474\n",
            "Val Loss: 1.3261, Val Acc: 0.4254, Val F1: 0.3953\n",
            "Overfitting Gap: 0.0220\n",
            "  No improvement (6/7)\n",
            "\n",
            "Epoch 25/30\n",
            "Train Loss: 1.3047, Train Acc: 0.4363\n",
            "Val Loss: 1.3292, Val Acc: 0.4309, Val F1: 0.3970\n",
            "Overfitting Gap: 0.0053\n",
            "  No improvement (7/7)\n",
            "  Early stopping triggered!\n",
            "\n",
            "================================================================================\n",
            "FOLD 2 FINAL RESULTS:\n",
            "================================================================================\n",
            "Accuracy:  0.4420\n",
            "Precision: 0.4388\n",
            "Recall:    0.4420\n",
            "F1-Score:  0.4102\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 1     0.3333    0.2647    0.2951        34\n",
            "   Cluster 2     0.4146    0.5152    0.4595        33\n",
            "   Cluster 3     0.5600    0.6512    0.6022        43\n",
            "   Cluster 4     0.4444    0.1053    0.1702        38\n",
            "   Cluster 5     0.4074    0.6667    0.5057        33\n",
            "\n",
            "    accuracy                         0.4420       181\n",
            "   macro avg     0.4320    0.4406    0.4065       181\n",
            "weighted avg     0.4388    0.4420    0.4102       181\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FOLD 3/5\n",
            "================================================================================\n",
            "Train size: 722, Val size: 181\n",
            "\n",
            "Epoch 1/30\n",
            "Train Loss: 1.6077, Train Acc: 0.2313\n",
            "Val Loss: 1.5761, Val Acc: 0.3702, Val F1: 0.2891\n",
            "Overfitting Gap: -0.1389\n",
            "  ✓ New best F1: 0.2891\n",
            "\n",
            "Epoch 2/30\n",
            "Train Loss: 1.5791, Train Acc: 0.2812\n",
            "Val Loss: 1.5356, Val Acc: 0.4144, Val F1: 0.3766\n",
            "Overfitting Gap: -0.1332\n",
            "  ✓ New best F1: 0.3766\n",
            "\n",
            "Epoch 3/30\n",
            "Train Loss: 1.5363, Train Acc: 0.3213\n",
            "Val Loss: 1.5054, Val Acc: 0.3978, Val F1: 0.3456\n",
            "Overfitting Gap: -0.0765\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 4/30\n",
            "Train Loss: 1.4870, Train Acc: 0.3587\n",
            "Val Loss: 1.4822, Val Acc: 0.4144, Val F1: 0.3713\n",
            "Overfitting Gap: -0.0556\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 5/30\n",
            "Train Loss: 1.4644, Train Acc: 0.3698\n",
            "Val Loss: 1.4603, Val Acc: 0.4144, Val F1: 0.3761\n",
            "Overfitting Gap: -0.0446\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 6/30\n",
            "Train Loss: 1.4415, Train Acc: 0.3753\n",
            "Val Loss: 1.4432, Val Acc: 0.4309, Val F1: 0.3914\n",
            "Overfitting Gap: -0.0556\n",
            "  ✓ New best F1: 0.3914\n",
            "\n",
            "Epoch 7/30\n",
            "Train Loss: 1.4233, Train Acc: 0.4224\n",
            "Val Loss: 1.4350, Val Acc: 0.4365, Val F1: 0.3944\n",
            "Overfitting Gap: -0.0140\n",
            "  ✓ New best F1: 0.3944\n",
            "\n",
            "Epoch 8/30\n",
            "Train Loss: 1.4040, Train Acc: 0.4238\n",
            "Val Loss: 1.4190, Val Acc: 0.4420, Val F1: 0.4006\n",
            "Overfitting Gap: -0.0182\n",
            "  ✓ New best F1: 0.4006\n",
            "\n",
            "Epoch 9/30\n",
            "Train Loss: 1.3677, Train Acc: 0.4197\n",
            "Val Loss: 1.4170, Val Acc: 0.4365, Val F1: 0.3949\n",
            "Overfitting Gap: -0.0168\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 10/30\n",
            "Train Loss: 1.3827, Train Acc: 0.4183\n",
            "Val Loss: 1.4074, Val Acc: 0.4254, Val F1: 0.3812\n",
            "Overfitting Gap: -0.0071\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 11/30\n",
            "Train Loss: 1.3828, Train Acc: 0.4363\n",
            "Val Loss: 1.4009, Val Acc: 0.4199, Val F1: 0.3868\n",
            "Overfitting Gap: 0.0164\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 12/30\n",
            "Train Loss: 1.3689, Train Acc: 0.4197\n",
            "Val Loss: 1.3980, Val Acc: 0.4420, Val F1: 0.4121\n",
            "Overfitting Gap: -0.0223\n",
            "  ✓ New best F1: 0.4121\n",
            "\n",
            "Epoch 13/30\n",
            "Train Loss: 1.3634, Train Acc: 0.4100\n",
            "Val Loss: 1.3910, Val Acc: 0.4365, Val F1: 0.4104\n",
            "Overfitting Gap: -0.0265\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 14/30\n",
            "Train Loss: 1.3487, Train Acc: 0.4321\n",
            "Val Loss: 1.3983, Val Acc: 0.4530, Val F1: 0.4192\n",
            "Overfitting Gap: -0.0209\n",
            "  ✓ New best F1: 0.4192\n",
            "\n",
            "Epoch 15/30\n",
            "Train Loss: 1.3418, Train Acc: 0.4141\n",
            "Val Loss: 1.3980, Val Acc: 0.4420, Val F1: 0.4097\n",
            "Overfitting Gap: -0.0279\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 16/30\n",
            "Train Loss: 1.3491, Train Acc: 0.4488\n",
            "Val Loss: 1.3890, Val Acc: 0.4530, Val F1: 0.4277\n",
            "Overfitting Gap: -0.0043\n",
            "  ✓ New best F1: 0.4277\n",
            "\n",
            "Epoch 17/30\n",
            "Train Loss: 1.3135, Train Acc: 0.4889\n",
            "Val Loss: 1.3839, Val Acc: 0.4475, Val F1: 0.4171\n",
            "Overfitting Gap: 0.0414\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 18/30\n",
            "Train Loss: 1.2988, Train Acc: 0.4640\n",
            "Val Loss: 1.3791, Val Acc: 0.4309, Val F1: 0.4037\n",
            "Overfitting Gap: 0.0330\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 19/30\n",
            "Train Loss: 1.3257, Train Acc: 0.4404\n",
            "Val Loss: 1.3835, Val Acc: 0.4586, Val F1: 0.4307\n",
            "Overfitting Gap: -0.0181\n",
            "  ✓ New best F1: 0.4307\n",
            "\n",
            "Epoch 20/30\n",
            "Train Loss: 1.3116, Train Acc: 0.4612\n",
            "Val Loss: 1.3799, Val Acc: 0.4475, Val F1: 0.4173\n",
            "Overfitting Gap: 0.0137\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 21/30\n",
            "Train Loss: 1.3449, Train Acc: 0.4640\n",
            "Val Loss: 1.3726, Val Acc: 0.4586, Val F1: 0.4378\n",
            "Overfitting Gap: 0.0054\n",
            "  ✓ New best F1: 0.4378\n",
            "\n",
            "Epoch 22/30\n",
            "Train Loss: 1.2824, Train Acc: 0.4598\n",
            "Val Loss: 1.3708, Val Acc: 0.4586, Val F1: 0.4394\n",
            "Overfitting Gap: 0.0013\n",
            "  ✓ New best F1: 0.4394\n",
            "\n",
            "Epoch 23/30\n",
            "Train Loss: 1.2978, Train Acc: 0.4695\n",
            "Val Loss: 1.3781, Val Acc: 0.4696, Val F1: 0.4434\n",
            "Overfitting Gap: -0.0001\n",
            "  ✓ New best F1: 0.4434\n",
            "\n",
            "Epoch 24/30\n",
            "Train Loss: 1.3169, Train Acc: 0.4474\n",
            "Val Loss: 1.3820, Val Acc: 0.4420, Val F1: 0.4022\n",
            "Overfitting Gap: 0.0054\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 25/30\n",
            "Train Loss: 1.2692, Train Acc: 0.4681\n",
            "Val Loss: 1.3814, Val Acc: 0.4641, Val F1: 0.4361\n",
            "Overfitting Gap: 0.0041\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 26/30\n",
            "Train Loss: 1.2601, Train Acc: 0.4889\n",
            "Val Loss: 1.3768, Val Acc: 0.4365, Val F1: 0.4075\n",
            "Overfitting Gap: 0.0525\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 27/30\n",
            "Train Loss: 1.3321, Train Acc: 0.4640\n",
            "Val Loss: 1.3761, Val Acc: 0.4309, Val F1: 0.3931\n",
            "Overfitting Gap: 0.0330\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 28/30\n",
            "Train Loss: 1.2832, Train Acc: 0.4668\n",
            "Val Loss: 1.3618, Val Acc: 0.4475, Val F1: 0.4245\n",
            "Overfitting Gap: 0.0192\n",
            "  No improvement (5/7)\n",
            "\n",
            "Epoch 29/30\n",
            "Train Loss: 1.2980, Train Acc: 0.4640\n",
            "Val Loss: 1.3684, Val Acc: 0.4641, Val F1: 0.4395\n",
            "Overfitting Gap: -0.0001\n",
            "  No improvement (6/7)\n",
            "\n",
            "Epoch 30/30\n",
            "Train Loss: 1.2688, Train Acc: 0.4765\n",
            "Val Loss: 1.3645, Val Acc: 0.4475, Val F1: 0.4147\n",
            "Overfitting Gap: 0.0289\n",
            "  No improvement (7/7)\n",
            "  Early stopping triggered!\n",
            "\n",
            "================================================================================\n",
            "FOLD 3 FINAL RESULTS:\n",
            "================================================================================\n",
            "Accuracy:  0.4696\n",
            "Precision: 0.4696\n",
            "Recall:    0.4696\n",
            "F1-Score:  0.4434\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 1     0.4231    0.3235    0.3667        34\n",
            "   Cluster 2     0.4375    0.4242    0.4308        33\n",
            "   Cluster 3     0.5172    0.6977    0.5941        43\n",
            "   Cluster 4     0.5000    0.1795    0.2642        39\n",
            "   Cluster 5     0.4510    0.7188    0.5542        32\n",
            "\n",
            "    accuracy                         0.4696       181\n",
            "   macro avg     0.4658    0.4687    0.4420       181\n",
            "weighted avg     0.4696    0.4696    0.4434       181\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FOLD 4/5\n",
            "================================================================================\n",
            "Train size: 723, Val size: 180\n",
            "\n",
            "Epoch 1/30\n",
            "Train Loss: 1.6271, Train Acc: 0.1992\n",
            "Val Loss: 1.5772, Val Acc: 0.3556, Val F1: 0.3373\n",
            "Overfitting Gap: -0.1564\n",
            "  ✓ New best F1: 0.3373\n",
            "\n",
            "Epoch 2/30\n",
            "Train Loss: 1.5794, Train Acc: 0.2725\n",
            "Val Loss: 1.5352, Val Acc: 0.3944, Val F1: 0.3757\n",
            "Overfitting Gap: -0.1220\n",
            "  ✓ New best F1: 0.3757\n",
            "\n",
            "Epoch 3/30\n",
            "Train Loss: 1.5439, Train Acc: 0.3292\n",
            "Val Loss: 1.4957, Val Acc: 0.4500, Val F1: 0.4016\n",
            "Overfitting Gap: -0.1208\n",
            "  ✓ New best F1: 0.4016\n",
            "\n",
            "Epoch 4/30\n",
            "Train Loss: 1.5029, Train Acc: 0.3472\n",
            "Val Loss: 1.4631, Val Acc: 0.4333, Val F1: 0.3897\n",
            "Overfitting Gap: -0.0862\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 5/30\n",
            "Train Loss: 1.4755, Train Acc: 0.3748\n",
            "Val Loss: 1.4277, Val Acc: 0.4556, Val F1: 0.4052\n",
            "Overfitting Gap: -0.0807\n",
            "  ✓ New best F1: 0.4052\n",
            "\n",
            "Epoch 6/30\n",
            "Train Loss: 1.4796, Train Acc: 0.3721\n",
            "Val Loss: 1.4039, Val Acc: 0.4278, Val F1: 0.3836\n",
            "Overfitting Gap: -0.0557\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 7/30\n",
            "Train Loss: 1.4243, Train Acc: 0.3817\n",
            "Val Loss: 1.3856, Val Acc: 0.4444, Val F1: 0.4026\n",
            "Overfitting Gap: -0.0627\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 8/30\n",
            "Train Loss: 1.4243, Train Acc: 0.4177\n",
            "Val Loss: 1.3721, Val Acc: 0.4278, Val F1: 0.3802\n",
            "Overfitting Gap: -0.0101\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 9/30\n",
            "Train Loss: 1.4121, Train Acc: 0.3983\n",
            "Val Loss: 1.3607, Val Acc: 0.4333, Val F1: 0.3984\n",
            "Overfitting Gap: -0.0350\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 10/30\n",
            "Train Loss: 1.4104, Train Acc: 0.4136\n",
            "Val Loss: 1.3546, Val Acc: 0.4167, Val F1: 0.3631\n",
            "Overfitting Gap: -0.0031\n",
            "  No improvement (5/7)\n",
            "\n",
            "Epoch 11/30\n",
            "Train Loss: 1.4063, Train Acc: 0.4149\n",
            "Val Loss: 1.3484, Val Acc: 0.4389, Val F1: 0.3851\n",
            "Overfitting Gap: -0.0240\n",
            "  No improvement (6/7)\n",
            "\n",
            "Epoch 12/30\n",
            "Train Loss: 1.3915, Train Acc: 0.4149\n",
            "Val Loss: 1.3525, Val Acc: 0.4500, Val F1: 0.4138\n",
            "Overfitting Gap: -0.0351\n",
            "  ✓ New best F1: 0.4138\n",
            "\n",
            "Epoch 13/30\n",
            "Train Loss: 1.3663, Train Acc: 0.4288\n",
            "Val Loss: 1.3414, Val Acc: 0.4333, Val F1: 0.3806\n",
            "Overfitting Gap: -0.0046\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 14/30\n",
            "Train Loss: 1.3519, Train Acc: 0.4454\n",
            "Val Loss: 1.3374, Val Acc: 0.4333, Val F1: 0.3835\n",
            "Overfitting Gap: 0.0120\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 15/30\n",
            "Train Loss: 1.3790, Train Acc: 0.4177\n",
            "Val Loss: 1.3478, Val Acc: 0.4167, Val F1: 0.3801\n",
            "Overfitting Gap: 0.0010\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 16/30\n",
            "Train Loss: 1.3778, Train Acc: 0.4205\n",
            "Val Loss: 1.3361, Val Acc: 0.4500, Val F1: 0.4109\n",
            "Overfitting Gap: -0.0295\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 17/30\n",
            "Train Loss: 1.3473, Train Acc: 0.4329\n",
            "Val Loss: 1.3336, Val Acc: 0.4444, Val F1: 0.4133\n",
            "Overfitting Gap: -0.0115\n",
            "  No improvement (5/7)\n",
            "\n",
            "Epoch 18/30\n",
            "Train Loss: 1.3692, Train Acc: 0.4191\n",
            "Val Loss: 1.3379, Val Acc: 0.4556, Val F1: 0.4286\n",
            "Overfitting Gap: -0.0365\n",
            "  ✓ New best F1: 0.4286\n",
            "\n",
            "Epoch 19/30\n",
            "Train Loss: 1.3359, Train Acc: 0.4205\n",
            "Val Loss: 1.3352, Val Acc: 0.4389, Val F1: 0.4058\n",
            "Overfitting Gap: -0.0184\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 20/30\n",
            "Train Loss: 1.3291, Train Acc: 0.4467\n",
            "Val Loss: 1.3340, Val Acc: 0.4222, Val F1: 0.3834\n",
            "Overfitting Gap: 0.0245\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 21/30\n",
            "Train Loss: 1.3375, Train Acc: 0.4440\n",
            "Val Loss: 1.3365, Val Acc: 0.4500, Val F1: 0.4205\n",
            "Overfitting Gap: -0.0060\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 22/30\n",
            "Train Loss: 1.3492, Train Acc: 0.4288\n",
            "Val Loss: 1.3307, Val Acc: 0.4611, Val F1: 0.4358\n",
            "Overfitting Gap: -0.0323\n",
            "  ✓ New best F1: 0.4358\n",
            "\n",
            "Epoch 23/30\n",
            "Train Loss: 1.3369, Train Acc: 0.4385\n",
            "Val Loss: 1.3315, Val Acc: 0.4389, Val F1: 0.4062\n",
            "Overfitting Gap: -0.0004\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 24/30\n",
            "Train Loss: 1.3416, Train Acc: 0.4412\n",
            "Val Loss: 1.3257, Val Acc: 0.4278, Val F1: 0.3834\n",
            "Overfitting Gap: 0.0134\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 25/30\n",
            "Train Loss: 1.3432, Train Acc: 0.4426\n",
            "Val Loss: 1.3331, Val Acc: 0.4500, Val F1: 0.4098\n",
            "Overfitting Gap: -0.0074\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 26/30\n",
            "Train Loss: 1.3381, Train Acc: 0.4219\n",
            "Val Loss: 1.3266, Val Acc: 0.4444, Val F1: 0.4074\n",
            "Overfitting Gap: -0.0226\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 27/30\n",
            "Train Loss: 1.3500, Train Acc: 0.4343\n",
            "Val Loss: 1.3294, Val Acc: 0.4333, Val F1: 0.3977\n",
            "Overfitting Gap: 0.0010\n",
            "  No improvement (5/7)\n",
            "\n",
            "Epoch 28/30\n",
            "Train Loss: 1.3491, Train Acc: 0.4260\n",
            "Val Loss: 1.3300, Val Acc: 0.4500, Val F1: 0.4188\n",
            "Overfitting Gap: -0.0240\n",
            "  No improvement (6/7)\n",
            "\n",
            "Epoch 29/30\n",
            "Train Loss: 1.3319, Train Acc: 0.4412\n",
            "Val Loss: 1.3285, Val Acc: 0.4444, Val F1: 0.4108\n",
            "Overfitting Gap: -0.0032\n",
            "  No improvement (7/7)\n",
            "  Early stopping triggered!\n",
            "\n",
            "================================================================================\n",
            "FOLD 4 FINAL RESULTS:\n",
            "================================================================================\n",
            "Accuracy:  0.4611\n",
            "Precision: 0.4565\n",
            "Recall:    0.4611\n",
            "F1-Score:  0.4358\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 1     0.4000    0.1818    0.2500        33\n",
            "   Cluster 2     0.3571    0.6061    0.4494        33\n",
            "   Cluster 3     0.5741    0.7209    0.6392        43\n",
            "   Cluster 4     0.4211    0.2105    0.2807        38\n",
            "   Cluster 5     0.5000    0.5455    0.5217        33\n",
            "\n",
            "    accuracy                         0.4611       180\n",
            "   macro avg     0.4505    0.4530    0.4282       180\n",
            "weighted avg     0.4565    0.4611    0.4358       180\n",
            "\n",
            "\n",
            "================================================================================\n",
            "FOLD 5/5\n",
            "================================================================================\n",
            "Train size: 723, Val size: 180\n",
            "\n",
            "Epoch 1/30\n",
            "Train Loss: 1.6263, Train Acc: 0.2089\n",
            "Val Loss: 1.5751, Val Acc: 0.3778, Val F1: 0.3329\n",
            "Overfitting Gap: -0.1689\n",
            "  ✓ New best F1: 0.3329\n",
            "\n",
            "Epoch 2/30\n",
            "Train Loss: 1.5688, Train Acc: 0.2974\n",
            "Val Loss: 1.5285, Val Acc: 0.4000, Val F1: 0.3339\n",
            "Overfitting Gap: -0.1026\n",
            "  ✓ New best F1: 0.3339\n",
            "\n",
            "Epoch 3/30\n",
            "Train Loss: 1.5408, Train Acc: 0.3347\n",
            "Val Loss: 1.4899, Val Acc: 0.4222, Val F1: 0.3565\n",
            "Overfitting Gap: -0.0875\n",
            "  ✓ New best F1: 0.3565\n",
            "\n",
            "Epoch 4/30\n",
            "Train Loss: 1.5226, Train Acc: 0.3126\n",
            "Val Loss: 1.4486, Val Acc: 0.4278, Val F1: 0.3490\n",
            "Overfitting Gap: -0.1152\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 5/30\n",
            "Train Loss: 1.4876, Train Acc: 0.3721\n",
            "Val Loss: 1.4161, Val Acc: 0.4278, Val F1: 0.3564\n",
            "Overfitting Gap: -0.0557\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 6/30\n",
            "Train Loss: 1.4532, Train Acc: 0.3734\n",
            "Val Loss: 1.3963, Val Acc: 0.4278, Val F1: 0.3709\n",
            "Overfitting Gap: -0.0543\n",
            "  ✓ New best F1: 0.3709\n",
            "\n",
            "Epoch 7/30\n",
            "Train Loss: 1.4350, Train Acc: 0.3914\n",
            "Val Loss: 1.3730, Val Acc: 0.4167, Val F1: 0.3476\n",
            "Overfitting Gap: -0.0252\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 8/30\n",
            "Train Loss: 1.4295, Train Acc: 0.3997\n",
            "Val Loss: 1.3589, Val Acc: 0.4167, Val F1: 0.3459\n",
            "Overfitting Gap: -0.0169\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 9/30\n",
            "Train Loss: 1.4124, Train Acc: 0.3928\n",
            "Val Loss: 1.3447, Val Acc: 0.4389, Val F1: 0.3811\n",
            "Overfitting Gap: -0.0461\n",
            "  ✓ New best F1: 0.3811\n",
            "\n",
            "Epoch 10/30\n",
            "Train Loss: 1.3970, Train Acc: 0.4149\n",
            "Val Loss: 1.3359, Val Acc: 0.4222, Val F1: 0.3593\n",
            "Overfitting Gap: -0.0073\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 11/30\n",
            "Train Loss: 1.3750, Train Acc: 0.4177\n",
            "Val Loss: 1.3331, Val Acc: 0.4167, Val F1: 0.3501\n",
            "Overfitting Gap: 0.0010\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 12/30\n",
            "Train Loss: 1.3715, Train Acc: 0.4246\n",
            "Val Loss: 1.3243, Val Acc: 0.4333, Val F1: 0.3672\n",
            "Overfitting Gap: -0.0087\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 13/30\n",
            "Train Loss: 1.3927, Train Acc: 0.4011\n",
            "Val Loss: 1.3239, Val Acc: 0.4278, Val F1: 0.3672\n",
            "Overfitting Gap: -0.0267\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 14/30\n",
            "Train Loss: 1.3427, Train Acc: 0.4177\n",
            "Val Loss: 1.3212, Val Acc: 0.4389, Val F1: 0.3874\n",
            "Overfitting Gap: -0.0212\n",
            "  ✓ New best F1: 0.3874\n",
            "\n",
            "Epoch 15/30\n",
            "Train Loss: 1.3445, Train Acc: 0.4440\n",
            "Val Loss: 1.3168, Val Acc: 0.4278, Val F1: 0.3775\n",
            "Overfitting Gap: 0.0162\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 16/30\n",
            "Train Loss: 1.3416, Train Acc: 0.4481\n",
            "Val Loss: 1.3169, Val Acc: 0.4333, Val F1: 0.3807\n",
            "Overfitting Gap: 0.0148\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 17/30\n",
            "Train Loss: 1.3628, Train Acc: 0.4315\n",
            "Val Loss: 1.3144, Val Acc: 0.4500, Val F1: 0.3966\n",
            "Overfitting Gap: -0.0185\n",
            "  ✓ New best F1: 0.3966\n",
            "\n",
            "Epoch 18/30\n",
            "Train Loss: 1.3283, Train Acc: 0.4661\n",
            "Val Loss: 1.3108, Val Acc: 0.4278, Val F1: 0.3835\n",
            "Overfitting Gap: 0.0383\n",
            "  No improvement (1/7)\n",
            "\n",
            "Epoch 19/30\n",
            "Train Loss: 1.3349, Train Acc: 0.4523\n",
            "Val Loss: 1.3097, Val Acc: 0.4111, Val F1: 0.3713\n",
            "Overfitting Gap: 0.0412\n",
            "  No improvement (2/7)\n",
            "\n",
            "Epoch 20/30\n",
            "Train Loss: 1.3056, Train Acc: 0.4537\n",
            "Val Loss: 1.3072, Val Acc: 0.4444, Val F1: 0.3927\n",
            "Overfitting Gap: 0.0092\n",
            "  No improvement (3/7)\n",
            "\n",
            "Epoch 21/30\n",
            "Train Loss: 1.3218, Train Acc: 0.4647\n",
            "Val Loss: 1.3111, Val Acc: 0.4389, Val F1: 0.3953\n",
            "Overfitting Gap: 0.0258\n",
            "  No improvement (4/7)\n",
            "\n",
            "Epoch 22/30\n",
            "Train Loss: 1.3031, Train Acc: 0.4426\n",
            "Val Loss: 1.3082, Val Acc: 0.4278, Val F1: 0.3927\n",
            "Overfitting Gap: 0.0148\n",
            "  No improvement (5/7)\n",
            "\n",
            "Epoch 23/30\n",
            "Train Loss: 1.3362, Train Acc: 0.4495\n",
            "Val Loss: 1.3084, Val Acc: 0.4333, Val F1: 0.3890\n",
            "Overfitting Gap: 0.0162\n",
            "  No improvement (6/7)\n",
            "\n",
            "Epoch 24/30\n",
            "Train Loss: 1.3328, Train Acc: 0.4385\n",
            "Val Loss: 1.3196, Val Acc: 0.4222, Val F1: 0.3818\n",
            "Overfitting Gap: 0.0162\n",
            "  No improvement (7/7)\n",
            "  Early stopping triggered!\n",
            "\n",
            "================================================================================\n",
            "FOLD 5 FINAL RESULTS:\n",
            "================================================================================\n",
            "Accuracy:  0.4500\n",
            "Precision: 0.4393\n",
            "Recall:    0.4500\n",
            "F1-Score:  0.3966\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 1     0.2174    0.1471    0.1754        34\n",
            "   Cluster 2     0.4194    0.4062    0.4127        32\n",
            "   Cluster 3     0.5893    0.7674    0.6667        43\n",
            "   Cluster 4     0.5000    0.0789    0.1364        38\n",
            "   Cluster 5     0.4219    0.8182    0.5567        33\n",
            "\n",
            "    accuracy                         0.4500       180\n",
            "   macro avg     0.4296    0.4436    0.3896       180\n",
            "weighted avg     0.4393    0.4500    0.3966       180\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. FINAL RESULTS"
      ],
      "metadata": {
        "id": "xgtTrIaTTVmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"5-FOLD CROSS VALIDATION SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(fold_results)\n",
        "print(\"\\nResults per fold:\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"AVERAGE PERFORMANCE ACROSS ALL FOLDS:\")\n",
        "print(\"=\"*80)\n",
        "avg_acc = results_df['accuracy'].mean()\n",
        "avg_f1 = results_df['f1'].mean()\n",
        "print(f\"Accuracy:  {avg_acc:.4f} ± {results_df['accuracy'].std():.4f}\")\n",
        "print(f\"Precision: {results_df['precision'].mean():.4f} ± {results_df['precision'].std():.4f}\")\n",
        "print(f\"Recall:    {results_df['recall'].mean():.4f} ± {results_df['recall'].std():.4f}\")\n",
        "print(f\"F1-Score:  {avg_f1:.4f} ± {results_df['f1'].std():.4f}\")\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('panns_audio_cv_results.csv', index=False)\n",
        "print(\"\\n✓ Results saved to 'panns_audio_cv_results.csv'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✅ PANNS AUDIO CLASSIFICATION COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n📊 PERFORMANCE SUMMARY:\")\n",
        "print(f\"  Audio (PANNs): {avg_f1:.1%}\")\n",
        "print(f\"  Dataset size: {len(df)} samples\")\n",
        "\n",
        "print(\"\\n💡 COMPARISON:\")\n",
        "print(f\"  Lyrics (BERT): ~45-55% F1\")\n",
        "print(f\"  MIDI (Orpheus): ~23% F1 (limited data)\")\n",
        "print(f\"  Audio (PANNs): ~{avg_f1:.0%} F1\")\n",
        "\n",
        "if avg_f1 > 0.50:\n",
        "    print(\"\\n🎉 Audio modality performs BEST!\")\n",
        "    print(\"This confirms audio is the strongest single modality.\")\n",
        "elif avg_f1 > 0.40:\n",
        "    print(\"\\n✓ Audio performs well!\")\n",
        "    print(\"Comparable to lyrics modality.\")\n",
        "else:\n",
        "    print(\"\\n⚠️ Audio performance below expectation\")\n",
        "    print(\"May need more data or different preprocessing.\")\n",
        "\n",
        "print(\"\\n📈 NEXT STEPS:\")\n",
        "print(\"  1. ✓ Lyrics modality (BERT) - DONE\")\n",
        "print(\"  2. ✓ MIDI modality (Orpheus) - DONE\")\n",
        "print(\"  3. ✓ Audio modality (PANNs) - DONE\")\n",
        "print(\"  4. ⏳ Multimodal Fusion - NEXT\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSWY3nn0TX8S",
        "outputId": "f98b6ceb-072f-4694-ce27-dfa49b4e0361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "5-FOLD CROSS VALIDATION SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Results per fold:\n",
            " fold  accuracy  precision   recall       f1\n",
            "    1  0.486188   0.469039 0.486188 0.454786\n",
            "    2  0.441989   0.438838 0.441989 0.410194\n",
            "    3  0.469613   0.469585 0.469613 0.443444\n",
            "    4  0.461111   0.456505 0.461111 0.435834\n",
            "    5  0.450000   0.439288 0.450000 0.396616\n",
            "\n",
            "================================================================================\n",
            "AVERAGE PERFORMANCE ACROSS ALL FOLDS:\n",
            "================================================================================\n",
            "Accuracy:  0.4618 ± 0.0172\n",
            "Precision: 0.4547 ± 0.0152\n",
            "Recall:    0.4618 ± 0.0172\n",
            "F1-Score:  0.4282 ± 0.0241\n",
            "\n",
            "✓ Results saved to 'panns_audio_cv_results.csv'\n",
            "\n",
            "================================================================================\n",
            "✅ PANNS AUDIO CLASSIFICATION COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "📊 PERFORMANCE SUMMARY:\n",
            "  Audio (PANNs): 42.8%\n",
            "  Dataset size: 903 samples\n",
            "\n",
            "💡 COMPARISON:\n",
            "  Lyrics (BERT): ~45-55% F1\n",
            "  MIDI (Orpheus): ~23% F1 (limited data)\n",
            "  Audio (PANNs): ~43% F1\n",
            "\n",
            "✓ Audio performs well!\n",
            "Comparable to lyrics modality.\n",
            "\n",
            "📈 NEXT STEPS:\n",
            "  1. ✓ Lyrics modality (BERT) - DONE\n",
            "  2. ✓ MIDI modality (Orpheus) - DONE\n",
            "  3. ✓ Audio modality (PANNs) - DONE\n",
            "  4. ⏳ Multimodal Fusion - NEXT\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}